# -*- coding: utf-8 -*-
"""spark_modelos_de_classificacao.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wjv1b5pIPyNA9hOruSX-2z-FfmaHEBEX

# **Projeto**

Ajudar o time de marketing a prever se um cliente vai cancelar o serviço ou não, pois eles estão notando um problema com o churn.

Nossa proposta para esse problema é criar um modelo de machine learning capaz de fazer a classificação entre clientes que vão cancelar o serviço e os que não vão.

Para isso, vamos utilizar uma base de dados fornecida pelo time de marketing contendo informações sobre esse cliente, como o tipo de serviço que ele contratou, há quanto tempo seu contrato está vigente, etc. Com essas informações, criaremos o modelo.

Ao final do pipeline, entregaremos um modelo capaz de realizar a classificação de novos clientes entre provável cancelamento do serviço ou não, oferecendo essa previsão. Ou seja, teremos um modelo com tuning, otimizado para o nosso problema.

# **Configuração do Ambiente do Google Colab**
"""

# Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Spark
!pip install pyspark

"""# **Configuração do Script**"""

# Importação dos Pacotes
# ==============================================================================

# Spark SQL
from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import *

# Spark ML
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

# Outras

# Conexões Externas
# ==============================================================================

# Spark
spark = SparkSession.builder \
    .master('local[*]') \
    .appName("Spark Modelos de Classificação") \
    .getOrCreate()

# Atributos e Variáveis de Ambiente
# ==============================================================================
filename = '/content/drive/MyDrive/Python/data/in/churn/churn_clientes.csv'
v_seed = 101

"""# **Preparação do Arquivo de Origem**

## Leitura e Estruturação do Arquivo
"""

# Leitura do Arquivo
dados = spark.read.csv(filename, sep=',', header=True)

# Verifica o Schema dos Dados
dados.printSchema()

# Exibe uma amostra dos dados
dados.show(n=5, truncate=False)

dados.groupBy('Churn').count().show()

"""## Tratamento dos Dados"""

# Converter as Colunas que contém dados Booleanos "Sim/Não" para 1 e 0
# =====================================================================================

# Lista de Colunas Binárias
bool_cols = ['Churn', 'Conjuge', 'Dependentes', 'TelefoneFixo', 'MaisDeUmaLinhaTelefonica',
  'SegurancaOnline', 'BackupOnline', 'SeguroDispositivo', 'SuporteTecnico',
  'TVaCabo', 'StreamingFilmes', 'ContaCorreio']

# Montagem do Script
sql_cols = [when(col(c)=='Sim',1).otherwise(0).alias(c) for c in bool_cols]

# Inserção das outras Colunas no Script
for cols in reversed(dados.columns):
  if cols not in bool_cols:
    sql_cols.insert(0, cols)

# Aplica as alterações
df = dados.select(sql_cols)

# Printa o Schema dos Dados
df. printSchema()

# Exibe  uma amostra dos dados
df.show(n=5, truncate=False)

"""## Variáveis Dummy"""

internet = df.groupBy('id').pivot('Internet').agg(lit(1)).na.fill(0)
tipo_contrato = df.groupBy('id').pivot('TipoContrato').agg(lit(1)).na.fill(0)
metodo_pagamento = df.groupBy('id').pivot('MetodoPagamento').agg(lit(1)).na.fill(0)

# Unificação das Dummies e Estruturação do Tipo de Dados
df = df.join(internet, on='id', how='inner')\
  .join(tipo_contrato, on='id', how='inner')\
  .join(metodo_pagamento, on='id', how='inner')\
  .select(
        'id',
        col('Mais65anos').cast(IntegerType()),
        col('MesesDeContrato').cast(IntegerType()),
        col('MesesCobrados').cast(DoubleType()),
        'Churn',
        'Conjuge',
        'Dependentes',
        'TelefoneFixo',
        'MaisDeUmaLinhaTelefonica',
        'SegurancaOnline',
        'BackupOnline',
        'SeguroDispositivo',
        'SuporteTecnico',
        'TVaCabo',
        'StreamingFilmes',
        'ContaCorreio',
        col('DSL').alias('Internet_DSL'),
        col('FibraOptica').alias('Internet_FibraOptica'),
        col('Nao').alias('Internet_Nao'),
        col('Mensalmente').alias('TipoContrato_Mensalmente'),
        col('UmAno').alias('TipoContrato_UmAno'),
        col('DoisAnos').alias('TipoContrato_DoisAnos'),
        col('DebitoEmConta').alias('MetodoPagamento_DebitoEmConta'),
        col('CartaoCredito').alias('MetodoPagamento_CartaoCredito'),
        col('BoletoEletronico').alias('MetodoPagamento_BoletoEletronico'),
        col('Boleto').alias('MetodoPagamento_Boleto')
  )

"""# **Regressão Logistica**

A regressão logística é um método popular para prever uma resposta categórica. É um caso especial de modelos lineares generalizados que prevê a probabilidade dos resultados. No "spark.ml", a regressão logística pode ser usada para prever um resultado binário usando a regressão logística binomial, ou pode ser usada para prever um resultado multiclasse usando a regressão logística multinomial. Use o parâmetro "family" para selecionar entre esses dois algoritmos, ou deixe-o sem definição e o Spark inferirá a variante correta.

A regressão logística multinomial pode ser usada para classificação binária definindo o parâmetro "family" como "multinomial". Ela produzirá dois conjuntos de coeficientes e dois interceptores.

Ao ajustar o modelo de regressão logística sem intercepto em um conjunto de dados com coluna constante não nula, o Spark MLlib retorna coeficientes zero para as colunas constantes não nulas. Esse comportamento é o mesmo do "glmnet" do R, mas diferente do LIBSVM.

## Preparação de Dados Para o Modelo
"""

# Renomear a coluna target para o parâmetro esperado
df = df.withColumnRenamed('Churn', 'label')

# Seleção de Features
x = df.columns
x.remove('label')
x.remove('id')

assembler = VectorAssembler(inputCols=x, outputCol='features')

df_prep = assembler.transform(df).select('features', 'label')

df_prep.show(n=10, truncate=False)

"""## Ajuste e Previsão"""

treino, teste = df_prep.randomSplit([0.7,0.3], seed=v_seed)

print(f'Dados Treino {treino.count()}')
print(f'Dados Teste {teste.count()}')

# Cria o objeto de Regressão Logistica
lr = LogisticRegression()

# Ajusta os dados de Treino ao Modelo
modelo_lr = lr.fit(treino)

# Realiza as previsões com os dados de Teste
prev_lr_treino = modelo_lr.transform(treino)
prev_lr_teste = modelo_lr.transform(teste)

# Exibe uma amostra de dados
prev_lr_treino.show(n=10, truncate=False)

"""## Métricas de Avaliação"""

# Resumo do Modelo
evaluator = MulticlassClassificationEvaluator()

print("Acurácia: %f" % evaluator.evaluate(prev_lr_treino, {evaluator.metricName: "accuracy"}))
print("Precisão: %f" % evaluator.evaluate(prev_lr_treino, {evaluator.metricName: "precisionByLabel", evaluator.metricLabel: 1}))
print("Recall: %f" % evaluator.evaluate(prev_lr_treino, {evaluator.metricName: "recallByLabel", evaluator.metricLabel: 1}))
print("F1: %f" % evaluator.evaluate(prev_lr_treino, {evaluator.metricName: "fMeasureByLabel", evaluator.metricLabel: 1}))

# Matrix de Confusão
matrix_confusao = prev_lr_treino.groupBy("label").pivot("prediction").count().na.fill(0)
matrix_confusao.show()

"""# **Árvore de Decisão**

## Ajuste e Previsão
"""

dtc = DecisionTreeClassifier(seed=v_seed)

modelo_dtc = dtc.fit(treino)

prev_dtc_treino = modelo_dtc.transform(treino)
prev_dtc_teste = modelo_dtc.transform(teste)

prev_lr_teste.show()

"""## Métricas de Avaliação"""

# Resumo do Modelo
evaluator = MulticlassClassificationEvaluator()

print("Acurácia: %f" % evaluator.evaluate(prev_dtc_treino, {evaluator.metricName: "accuracy"}))
print("Precisão: %f" % evaluator.evaluate(prev_dtc_treino, {evaluator.metricName: "precisionByLabel", evaluator.metricLabel: 1}))
print("Recall: %f" % evaluator.evaluate(prev_dtc_treino, {evaluator.metricName: "recallByLabel", evaluator.metricLabel: 1}))
print("F1: %f" % evaluator.evaluate(prev_dtc_treino, {evaluator.metricName: "fMeasureByLabel", evaluator.metricLabel: 1}))

# Matrix de Confusão
matrix_confusao = prev_dtc_treino.groupBy("label").pivot("prediction").count().na.fill(0)
matrix_confusao.show()

"""# **Random Forest**"""

rf = RandomForestClassifier(seed=v_seed)
modelo_rf = rf.fit(treino)
prev_rf_treino = modelo_rf.transform(treino)
prev_rf_teste = modelo_rf.transform(teste)

prev_rf_teste.show()

"""## Métricas de Avaliação"""

# Resumo do Modelo
evaluator = MulticlassClassificationEvaluator()

print("Acurácia: %f" % evaluator.evaluate(prev_rf_treino, {evaluator.metricName: "accuracy"}))
print("Precisão: %f" % evaluator.evaluate(prev_rf_treino, {evaluator.metricName: "precisionByLabel", evaluator.metricLabel: 1}))
print("Recall: %f" % evaluator.evaluate(prev_rf_treino, {evaluator.metricName: "recallByLabel", evaluator.metricLabel: 1}))
print("F1: %f" % evaluator.evaluate(prev_rf_treino, {evaluator.metricName: "fMeasureByLabel", evaluator.metricLabel: 1}))

# Matrix de Confusão
matrix_confusao = prev_rf_treino.groupBy("label").pivot("prediction").count().na.fill(0)
matrix_confusao.show()