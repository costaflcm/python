# -*- coding: utf-8 -*-
"""pyspark_lr_imoveis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X_deR5X3p0m2uEwFVCyr5Pz9NXCh9VnJ

# Problemática

Prever o preços dos imóveis com base nas características de cadastro.

# Configuração do Ambiente do Google Colab
"""

# Google Drive
from google.colab import drive
drive.mount('/content/drive')

"""**Documentação do Spark**

https://spark.apache.org/docs/latest/api/python/
https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/index.html
https://spark.apache.org/docs/latest/api/python/reference/pyspark.ss/index.html
https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html
https://spark.apache.org/docs/latest/api/python/reference/pyspark.html
"""

# Spark
# Atualizando os pacotes do Linux
!apt-get update -qq

# Instalação do Java
!apt-get install openjdk-8-jdk-headless -qq > /dev/null

# Instalação do Spark
!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz
!tar xf spark-3.1.2-bin-hadoop2.7.tgz
!pip install -q findspark

# Configuração do Ambiente
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.1.2-bin-hadoop2.7"
import findspark
findspark.init()

"""# Configuração do Script"""

# Importação dos Pacotes
# ==============================================================================

# SQL
from pyspark.sql import SparkSession
from pyspark.sql.types import IntegerType, DoubleType
from pyspark.sql.functions import col, count, when, isnull, isnan, trim, lit, round

# ML
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.stat import Correlation
from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor
from pyspark.ml.evaluation import RegressionEvaluator
from pyspark.ml.tuning import CrossValidator, ParamGridBuilder

# Outras
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Conexões Externas
# ==============================================================================

# Spark
spark = SparkSession.builder \
    .master('local[*]') \
    .appName("Regressão Linear") \
    .getOrCreate()

# Atributos e Variáveis de Ambiente
# ==============================================================================
filename = '/content/drive/MyDrive/Python/data/in/imoveis/imoveis.json'
v_seed = 101

# Funções de Apoio
# ==============================================================================
def set_metrica(modelo, tipo_dado, r2, rsme):
  """
  Função que retorna o dicinário com os resultados das métricas.

  modelo: (str) Informe o nome do modelo avaliado
  tipo_dado (str): Teste ou Treino.
  r2 (double): Valor de R2.
  rsme (double): Valor de RSME
  """
  dic_eva = {'Modelo': modelo, 'Origem': tipo_dado, 'R2': r2, 'RSME': rsme}
  return dic_eva

# Outros Itens
# ==============================================================================
metricas_data = {'Modelo':[], 'Origem':[], 'R2':[],'RSME':[]}
metricas_df = pd.DataFrame(metricas_data)

"""# Preparação do Arquivo de Origem

## Leitura e Estruturação do Arquivo
"""

# Arquivo em Formato Json Identado, Realizando a Leitura Bruta
data = spark.read.json(filename)
data.printSchema()

# Convertendo o Dado Identado para Colunar
data = data.select('ident.*', 'listing.address.*','listing.address.location.*', 'listing.features.*', 'listing.prices.price',
            'listing.prices.tax.condo','listing.prices.tax.iptu', 'listing.types.*').drop('location')

# Alteração do Tipo de Dados (Caso saiba o tipo de dados é possível definilo na carga do arquivo)^
print('Schema Atual')
data.printSchema()

data = data.withColumn('usableAreas', col('usableAreas').cast(IntegerType()))\
    .withColumn('price', col('price').cast(DoubleType()))\
    .withColumn('condo', col('condo').cast(DoubleType()))\
    .withColumn('iptu', col('iptu').cast(DoubleType()))

print('Schema Após Alteração')
data.printSchema()

data.show(n=5, truncate=False)

# Renomeando as colunas para o padrão de dados
data = data.withColumnRenamed('customerID','id_cliente')\
  .withColumnRenamed('source', 'ds_canal_origem')\
  .withColumnRenamed('city', 'nm_cidade')\
  .withColumnRenamed('neighborhood', 'nm_bairro')\
  .withColumnRenamed('zone', 'nm_zona')\
  .withColumnRenamed('lat','cd_latitude')\
  .withColumnRenamed('lon', 'cd_longitude')\
  .withColumnRenamed('bathrooms','no_banheiros')\
  .withColumnRenamed('bedrooms', 'no_quartos')\
  .withColumnRenamed('floors', 'no_andares')\
  .withColumnRenamed('parkingSpaces', 'no_vagas_garagem')\
  .withColumnRenamed('suites', 'no_suites')\
  .withColumnRenamed('totalAreas', 'no_m2_total')\
  .withColumnRenamed('unitFloor', 'no_unidade')\
  .withColumnRenamed('unitsOnTheFloor', 'no_unidades_andar')\
  .withColumnRenamed('usableAreas', 'no_m2_util_total')\
  .withColumnRenamed('price', 'vl_preco')\
  .withColumnRenamed('condo', 'vl_condominio')\
  .withColumnRenamed('iptu', 'vl_iptu')\
  .withColumnRenamed('unit', 'ds_tipo_unidade')\
  .withColumnRenamed('usage', 'ds_tipo_uso')

data.show(n=5, truncate=False)

"""## Tratamento dos Dados"""

# Verificar o Tamanho do Dataset
print(f' Quantidade de Obervações: {data.count()}')
print(f' Quantidade de Variáveis: {len(data.columns)}')

# Seleção de Features / Colunas que serão utilizadas
data = data.drop('nm_cidade', 'cd_latitude', 'cd_longitude', 'no_m2_total')

# Verificar se Existem dados como NaN ou Nulos
# A Lista Abaixo cria o comando do case when varrendo todas as colunas
cmd_list = [count(when(isnan(c) | isnull(c), True)).alias(c) for c in data.columns]
cmd_list

data.select(cmd_list).show()

# Informações de condominio e IPTU são importantes por isso serão 0 zeradas
data = data.select('*').na.fill(0)
data.select(cmd_list).show()

data.show(n=5)

data.groupBy('ds_canal_origem').count().show()
data.groupBy('nm_bairro').count().show()
data.groupBy('ds_tipo_unidade').count().show()
data.groupBy('ds_tipo_uso').count().show()
data.groupBy('nm_zona').count().show()

# Serão Mantidos somente os dados de imóveis Residenciais
data = data.filter(col('ds_tipo_uso') == 'Residencial')

# Imóveis de Zonas Não Identificadas serão removidos
data = data.filter(col('nm_zona') != '')

"""## Preparação dos dados para o Modelo

### Variáveis Dummy
"""

zona = data.groupBy('id_cliente').pivot('nm_zona').agg(lit(1)).na.fill(0)
zona.show(n=5, truncate=False)

unidade = data.groupBy('id_cliente').pivot('ds_tipo_unidade').agg(lit(1)).na.fill(0)
unidade.show(n=5, truncate=False)

data = data.join(unidade, on='id_cliente', how='inner')
data = data.join(zona, on='id_cliente', how='inner')

"""### Vetorização"""

# x = features
x = ['no_banheiros', 'no_quartos', 'no_andares', 'no_vagas_garagem',
     'no_suites', 'no_unidade', 'no_unidades_andar', 'no_m2_util_total',
     'vl_condominio', 'vl_iptu', 'Apartamento', 'Casa','Outros',
     'Zona Central', 'Zona Norte', 'Zona Oeste', 'Zona Sul']

# Objeto de Vetorização
assembler = VectorAssembler(inputCols=x, outputCol='features')

# Preparação do Dataframe
data = data.withColumnRenamed('vl_preco', 'label')

# Preparando o dataset para as funções de ML do Spark
data_prep = assembler.transform(data).select('features', 'label')
data_prep.show(n=5, truncate=False)

"""### Separação dos Dados Entre Treino e Teste"""

treino, teste = data_prep.randomSplit([0.7,0.3], seed=v_seed)
print(f'Observações para Treino: {treino.count()}')
print(f'Observações para Teste: {teste.count()}')

"""# Exploração dos Dados"""

correlacao = Correlation.corr(data_prep,'features').collect()[0][0]

correlacao_df = pd.DataFrame(correlacao.toArray(), columns=x, index=x)

plt.figure(figsize=(8,8))
paleta = sns.color_palette("flare", as_cmap=True)
sns.heatmap(correlacao_df.round(1), annot= True, cmap=paleta)

"""# Regressão Linear"""

# Cria o objeto de Regressão Linear
lr = LinearRegression()

# Ajusta o modelo aos dados de Treinamento
modelo_lr = lr.fit(treino)

# Aplica as previsões com os dados.
prev_treino_lr = modelo_lr.transform(treino)
prev_teste_lr = modelo_lr.transform(teste)

# Avaliação do Modelo
lr_eva = RegressionEvaluator()

r2_treino = lr_eva.evaluate(prev_treino_lr, {lr_eva.metricName: 'r2'})
rsme_treino = lr_eva.evaluate(prev_treino_lr, {lr_eva.metricName: 'rmse'})

r2_teste = lr_eva.evaluate(prev_teste_lr, {lr_eva.metricName: 'r2'})
rsme_teste = lr_eva.evaluate(prev_teste_lr, {lr_eva.metricName: 'rmse'})

metricas_df = metricas_df.append(set_metrica('Regressão Linear', 'Treino', r2_treino, rsme_treino), ignore_index=True)
metricas_df = metricas_df.append(set_metrica('Regressão Linear', 'Teste', r2_teste, rsme_teste), ignore_index=True)

print(f'Métricas de Avaliação')
metricas_df

print(f'Modelo de Treino Head 10')
prev_treino_lr.select('features','label',round('prediction',1).alias('prediction')).show(n=10)

print(f'Modelo de Teste Head 10')
prev_teste_lr.select('features','label',round('prediction',1).alias('prediction')).show(n=10)

"""# Árvore de Decisão"""

# Cria o objeto de Árvore de Decisão
dtr = DecisionTreeRegressor(seed=v_seed, maxDepth=7)

# Ajusta os dados ao Modelo
modelo_dtr = dtr.fit(treino)

# Aplica as Previsões com os Dados
prev_treino_dtr = modelo_dtr.transform(treino)
prev_teste_dtr = modelo_dtr.transform(teste)

# Avaliação do Modelo
dtr_eva = RegressionEvaluator()

r2_treino = dtr_eva.evaluate(prev_treino_dtr, {dtr_eva.metricName: 'r2'})
rsme_treino = dtr_eva.evaluate(prev_treino_dtr, {dtr_eva.metricName: 'rmse'})

r2_teste = dtr_eva.evaluate(prev_teste_dtr, {dtr_eva.metricName: 'r2'})
rsme_teste = dtr_eva.evaluate(prev_teste_dtr, {dtr_eva.metricName: 'rmse'})

metricas_df = metricas_df.append(set_metrica('Árvore de Decisão', 'Treino', r2_treino, rsme_treino), ignore_index=True)
metricas_df = metricas_df.append(set_metrica('Árvore de Decisão', 'Teste', r2_teste, rsme_teste), ignore_index=True)

print(f'Métricas de Avaliação')
metricas_df

print(f'Modelo de Treino Head 10')
prev_treino_dtr.select('features','label',round('prediction',1).alias('prediction')).show(n=10)

print(f'Modelo de Teste Head 10')
prev_teste_dtr.select('features','label',round('prediction',1).alias('prediction')).show(n=10)

"""## Cross Validation"""

# Cria o objeto de Decision Tree, sem a passagem de parâmetros
dtr = DecisionTreeRegressor()

# Cria um grid com as possibilidades de parâmetros
grid = ParamGridBuilder()\
  .addGrid(dtr.maxDepth, [2, 5, 10])\
  .addGrid(dtr.maxBins, [10,32,45])\
  .build()

# Cria o objeto de avaliação do Modelo
dtr_eva = RegressionEvaluator()

# Cria o objeto Decision Tree com Cross Validation
dtr_cv = CrossValidator(
    estimator=dtr,
    estimatorParamMaps=grid,
    evaluator = dtr_eva,
    numFolds=3,
    seed=v_seed
)

# Ajusta os dados ao Modelo
modelo_dtr_cv = dtr_cv.fit(treino)

# Aplica as Previsões com os Dados
prev_treino_dtr_cv = modelo_dtr_cv.transform(treino)
prev_teste_dtr_cv = modelo_dtr_cv.transform(teste)

# Faz a avaliação do Modelo
r2_treino = dtr_eva.evaluate(prev_treino_dtr_cv, {dtr_eva.metricName: 'r2'})
rsme_treino = dtr_eva.evaluate(prev_treino_dtr_cv, {dtr_eva.metricName: 'rmse'})

r2_teste = dtr_eva.evaluate(prev_teste_dtr_cv, {dtr_eva.metricName: 'r2'})
rsme_teste = dtr_eva.evaluate(prev_teste_dtr_cv, {dtr_eva.metricName: 'rmse'})

metricas_df = metricas_df.append(set_metrica('Árvore de Decisão Cross Validation', 'Treino', r2_treino, rsme_treino), ignore_index=True)
metricas_df = metricas_df.append(set_metrica('Árvore de Decisão Cross Validation', 'Teste', r2_teste, rsme_teste), ignore_index=True)

print(f'Métricas de Avaliação')
metricas_df

print(f'Modelo de Treino Head 10')
prev_treino_dtr_cv.select('features','label',round('prediction',1).alias('prediction')).show(n=10)

print(f'Modelo de Teste Head 10')
prev_teste_dtr_cv.select('features','label',round('prediction',1).alias('prediction')).show(n=10)

"""# Random Forest"""

# Cria o objeto de Random Forest
rfr = RandomForestRegressor(seed=v_seed, maxDepth=7, numTrees=10)

# Ajusta os dados ao Modelo
modelo_rfr = rfr.fit(treino)

# Aplica as Previsões dos Dados
prev_treino_rfr = modelo_rfr.transform(treino)
prev_teste_rfr = modelo_rfr.transform(teste)

# Avaliação do Modelo
rfr_eva = RegressionEvaluator()

r2_treino = rfr_eva.evaluate(prev_treino_rfr, {rfr_eva.metricName: 'r2'})
rsme_treino = rfr_eva.evaluate(prev_treino_rfr, {rfr_eva.metricName: 'rmse'})

r2_teste = rfr_eva.evaluate(prev_teste_rfr, {rfr_eva.metricName: 'r2'})
rsme_teste = rfr_eva.evaluate(prev_teste_rfr, {rfr_eva.metricName: 'rmse'})

metricas_df = metricas_df.append(set_metrica('Floresta Randomica', 'Treino', r2_treino, rsme_treino), ignore_index=True)
metricas_df = metricas_df.append(set_metrica('Floresta Randomica', 'Teste', r2_teste, rsme_teste), ignore_index=True)

print(f'Métricas de Avaliação')
metricas_df

print(f'Modelo de Treino Head 10')
prev_treino_rfr.select('features','label',round('prediction',1).alias('prediction')).show(n=10)

print(f'Modelo de Teste Head 10')
prev_teste_rfr.select('features','label',round('prediction',1).alias('prediction')).show(n=10)

"""## Cross Validation"""

# Cria o objeto de Decision Tree, sem a passagem de parâmetros
rfr = RandomForestRegressor()

# Cria um grid com as possibilidades de parâmetros
grid = ParamGridBuilder()\
  .addGrid(rfr.maxDepth, [2, 5, 10])\
  .addGrid(rfr.maxBins, [10,32,45])\
  .addGrid(rfr.numTrees, [5,10,15])\
  .build()

# Cria o objeto de avaliação do Modelo
rfr_eva = RegressionEvaluator()

# Cria o objeto Decision Tree com Cross Validation
rfr_cv = CrossValidator(
    estimator=rfr,
    estimatorParamMaps=grid,
    evaluator = rfr_eva,
    numFolds=3,
    seed=v_seed
)

# Ajusta os dados ao Modelo
modelo_rfr_cv = dtr_cv.fit(treino)

# Aplica as Previsões com os Dados
prev_treino_rfr_cv = modelo_dtr_cv.transform(treino)
prev_teste_rfr_cv = modelo_dtr_cv.transform(teste)

# Faz a avaliação do Modelo
r2_treino = rfr_eva.evaluate(prev_treino_rfr_cv, {dtr_eva.metricName: 'r2'})
rsme_treino = rfr_eva.evaluate(prev_treino_rfr_cv, {dtr_eva.metricName: 'rmse'})

r2_teste = rfr_eva.evaluate(prev_teste_rfr_cv, {dtr_eva.metricName: 'r2'})
rsme_teste = rfr_eva.evaluate(prev_teste_rfr_cv, {dtr_eva.metricName: 'rmse'})

metricas_df = metricas_df.append(set_metrica('Floresta Randomica Cross Validation', 'Treino', r2_treino, rsme_treino), ignore_index=True)
metricas_df = metricas_df.append(set_metrica('Floresta Randomica Cross Validation', 'Teste', r2_teste, rsme_teste), ignore_index=True)

print(f'Métricas de Avaliação')
metricas_df

print(f'Modelo de Treino Head 10')
prev_treino_rfr_cv.select('features','label',round('prediction',1).alias('prediction')).show(n=10)

print(f'Modelo de Teste Head 10')
prev_teste_rfr_cv.select('features','label',round('prediction',1).alias('prediction')).show(n=10)

"""# Escolha do Melhor Modelo"""

metricas_df.query('Origem == "Treino"')\
  .sort_values(['R2', 'RSME'], ascending=[False, True])\
  .head(10)

metricas_df.query('Origem == "Teste"')\
  .sort_values(['R2', 'RSME'], ascending=[False, True])\
  .head(10)

"""# Aplicando o Modelo na Prática"""

x = ['no_banheiros', 'no_quartos', 'no_andares', 'no_vagas_garagem',
     'no_suites', 'no_unidade', 'no_unidades_andar', 'no_m2_util_total',
     'vl_condominio', 'vl_iptu', 'Apartamento', 'Casa','Outros',
     'Zona Central', 'Zona Norte', 'Zona Oeste', 'Zona Sul']

novo_imovel = [{
    'no_banheiros': 2,
    'no_quartos': 4,
    'no_andares': 1,
    'no_vagas_garagem': 2,
    'no_suites': 1,
    'no_unidade':17,
    'no_unidades_andar':4,
    'no_m2_util_total':120,
    'vl_condominio':600,
    'vl_iptu':0,
    'Apartamento':1,
    'Casa':0,
    'Outros':0,
    'Zona Central':0,
    'Zona Norte':0,
    'Zona Oeste':0,
    'Zona Sul':1,
    'label': 0}]

meu_imovel = spark.createDataFrame(novo_imovel)
assembler = VectorAssembler(inputCols = x, outputCol = 'features')
meu_lar_vetorizado = assembler.transform(meu_imovel).select('features', 'label')
modelo_rfr_cv.transform(meu_lar_vetorizado).show()